{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a83dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## download the EM-EARTH data and combine it to the model simulation\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import hashlib\n",
    "import glob\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def download_EM_ERATH (server = 'https://g-772fa5.cd4fe.0ec8.data.globus.org/6/published/publication_542/submitted_data/',\n",
    "                       groups = ['deterministic_hourly','deterministic_raw_daily','probabilistic_daily'],\n",
    "                       variables = ['prcp','tdew','tmean','trange'],\n",
    "                       regions = ['Asia','Europe','Africa','NorthAmerica','Oceania','SouthAmerica'],\n",
    "                       years = ['1950','1951','1952','1953','1954',\\\n",
    "                                '1955','1956','1957','1958','1959',\\\n",
    "                                '1960','1961','1962','1963','1964',\\\n",
    "                                '1965','1966','1967','1968','1969',\\\n",
    "                                '1970','1971','1972','1973','1974',\\\n",
    "                                '1975','1976','1977','1978','1979',\\\n",
    "                                '1980','1981','1982','1983','1984',\\\n",
    "                                '1985','1986','1987','1988','1989',\\\n",
    "                                '1990','1991','1992','1993','1994',\\\n",
    "                                '1995','1996','1997','1998','1999',\\\n",
    "                                '2000','2001','2002','2003','2004',\\\n",
    "                                '2005','2006','2007','2008','2009',\\\n",
    "                                '2010','2011','2012','2013','2014',\\\n",
    "                                '2015','2016','2017','2018','2019'],\n",
    "                       months = ['01','02','03','04','05','06',\\\n",
    "                                 '07','08','09','10','11','12'],\n",
    "                       ensembles = ['001','002','003','004','005',\\\n",
    "                                    '006','007','008','009','010',\\\n",
    "                                    '011','012','013','014','015',\\\n",
    "                                    '016','017','018','019','020',\\\n",
    "                                    '021','022','023','024','025'],\n",
    "                       root_save = '../EM_Earth_v1/'):\n",
    "    \n",
    "    \n",
    "    for group in groups:\n",
    "        \n",
    "        for year in years:\n",
    "            \n",
    "            for month in months:\n",
    "                \n",
    "                for variable in variables:\n",
    "                    \n",
    "                    if group == 'deterministic_raw_daily':\n",
    "                        \n",
    "                        file_name = 'EM_Earth_deterministic_daily_'+variable+'_'+year+month+'.nc'\n",
    "                        path      = group+'/'+variable+'/'\n",
    "                        link      = server+'EM_Earth_v1/'+path+file_name\n",
    "                        path_save = root_save + path\n",
    "                        if not os.path.isdir(path_save):\n",
    "                            os.makedirs(path_save)\n",
    "                        download_file (link,path_save,file_name)\n",
    "                    \n",
    "                    for region in regions:\n",
    "                            \n",
    "                            if group == 'deterministic_hourly' and variable != 'trange':\n",
    "                                \n",
    "                                file_name = 'EM_Earth_'+group+'_'+region+'_'+year+month+'.nc'\n",
    "                                path      = group+'/'+variable+'/'+region+'/'\n",
    "                                link      = server+'EM_Earth_v1/'+path+file_name\n",
    "                                path_save = root_save + path\n",
    "                                if not os.path.isdir(path_save):\n",
    "                                    os.makedirs(path_save)\n",
    "                                download_file (link,path_save,file_name)\n",
    "                        \n",
    "                            \n",
    "                            if group == 'probabilistic_daily':\n",
    "\n",
    "                                for ensemble in ensembles:\n",
    "\n",
    "                                    file_name = 'EM_Earth_probabilistic_daily_'+variable+'_'+region+'_'+\\\n",
    "                                    year+month+'_'+ensemble+'.nc'\n",
    "                                    path      = group+'/'+variable+'/'+region+'/'+year+month+'/'\n",
    "                                    link      = server+'EM_Earth_v1/'+path+file_name\n",
    "                                    path_save = root_save + path\n",
    "                                    if not os.path.isdir(path_save):\n",
    "                                        os.makedirs(path_save)\n",
    "                                    download_file (link,path_save,file_name)\n",
    "\n",
    "\n",
    "def download_file (link,path_save,file_name):\n",
    "    \n",
    "    \n",
    "    os.system('rm *.nc*')\n",
    "    downloaded = False\n",
    "    try_number = 1\n",
    "    while (not downloaded) and (try_number < 1000):\n",
    "        print('going to download '+file_name + ': '+str(try_number))\n",
    "        os.system('wget -nv '+link +' '+file_name)\n",
    "        #os.system('wget -O - link | tee file_name | md5sum > remote')\n",
    "        os.system('wget -O - '+link +' | md5sum > remote')\n",
    "        os.system('md5sum '+file_name+' > local')\n",
    "        md5_local = word_file('local')\n",
    "        md5_remote = word_file('remote')\n",
    "        print(md5_local, md5_remote)\n",
    "        if md5_local == md5_remote:\n",
    "            print('files are the same')\n",
    "            downloaded = True\n",
    "            os.system('mv '+ file_name +' '+path_save+file_name) # maybe test with mv\n",
    "        try_number = try_number + 1\n",
    "        os.system('rm *.nc*')\n",
    "\n",
    "\n",
    "def word_file(f):\n",
    "    with open(f) as file:\n",
    "        return file.read().split()[0]\n",
    "\n",
    "def merging_EM_ERATH  (variables = ['prcp','tdew','tmean','trange'],\n",
    "                       regions = ['Asia','Europe','Africa','NorthAmerica','Oceania','SouthAmerica'],\n",
    "                       years = ['1950','1951','1952','1953','1954',\\\n",
    "                                '1955','1956','1957','1958','1959',\\\n",
    "                                '1960','1961','1962','1963','1964',\\\n",
    "                                '1965','1966','1967','1968','1969',\\\n",
    "                                '1970','1971','1972','1973','1974',\\\n",
    "                                '1975','1976','1977','1978','1979',\\\n",
    "                                '1980','1981','1982','1983','1984',\\\n",
    "                                '1985','1986','1987','1988','1989',\\\n",
    "                                '1990','1991','1992','1993','1994',\\\n",
    "                                '1995','1996','1997','1998','1999',\\\n",
    "                                '2000','2001','2002','2003','2004',\\\n",
    "                                '2005','2006','2007','2008','2009',\\\n",
    "                                '2010','2011','2012','2013','2014',\\\n",
    "                                '2015','2016','2017','2018','2019'],\n",
    "                       months = ['01','02','03','04','05','06',\\\n",
    "                                 '07','08','09','10','11','12'],\n",
    "                       ensembles = ['001','002','003','004','005',\\\n",
    "                                    '006','007','008','009','010',\\\n",
    "                                    '011','012','013','014','015',\\\n",
    "                                    '016','017','018','019','020',\\\n",
    "                                    '021','022','023','024','025'],\n",
    "                       root_save = '../EM_Earth_v1/'):\n",
    "    \n",
    "    \n",
    "    for year in years:\n",
    "\n",
    "        for month in months:\n",
    "\n",
    "            for variable in variables:\n",
    "                \n",
    "                # file_name\n",
    "                file_name = root_save+'deterministic_raw_daily/'+variable+'/'+\\\n",
    "                'EM_Earth_deterministic_daily_'+variable+'_'+year+month+'.nc'\n",
    "                \n",
    "                # open dataset\n",
    "                ds_global = xr.open_dataset(file_name)\n",
    "                #print(ds_global.lon[0:3])\n",
    "                \n",
    "                # reorganize the variables to time, lat, lon\n",
    "                ds_global = ds_global.transpose('time', 'lat', 'lon')\n",
    "                \n",
    "                mask_sum ={}\n",
    "                # replace the varibales with 0.00\n",
    "                for v in ds_global.data_vars:\n",
    "                    ds_global [v][:] = 0.00\n",
    "                    mask_sum[v] = np.zeros([1800, 3600])\n",
    "                \n",
    "                # loop over the ensembles\n",
    "                for ensemble in ensembles:\n",
    "                    \n",
    "                    #  read the files\n",
    "                    file_names = root_save+'probabilistic_daily/'+variable+'/*/'+\\\n",
    "                                           year+month+'/*'+ensemble+'.nc'\n",
    "                    file_names = glob.glob(file_names)\n",
    "                    \n",
    "                    #\n",
    "                    for file_name in file_names:\n",
    "                        print(file_name)\n",
    "                        ds = xr.open_dataset(file_name)\n",
    "                        #print(ds.data_vars)\n",
    "                        ds = ds.transpose('time', 'lat', 'lon') # making sure the order\n",
    "                        \n",
    "                        if ds.lon.values.max() > 180:\n",
    "                            # Asia\n",
    "                            ds1 = ds.sel(lon=slice(None, 179.975))\n",
    "                            ds2 = ds.sel(lon=slice(179.975, None))\n",
    "                            ds2['lon'] = ds2['lon'] - 360\n",
    "                            ds_global, mask_sum = fill_cont_to_globe(ds1, ds_global, mask_sum)\n",
    "                            ds_global, mask_sum = fill_cont_to_globe(ds2, ds_global, mask_sum)\n",
    "                        elif ds.lon.values.min() < -180:\n",
    "                            # North America\n",
    "                            ds1 = ds.sel(lon=slice(None, -179.975))\n",
    "                            ds2 = ds.sel(lon=slice(-179.975, None))\n",
    "                            ds1['lon'] = ds1['lon'] + 360\n",
    "                            ds_global, mask_sum = fill_cont_to_globe(ds1, ds_global, mask_sum)\n",
    "                            ds_global, mask_sum = fill_cont_to_globe(ds2, ds_global, mask_sum)\n",
    "                        else:\n",
    "                            ds_global, mask_sum = fill_cont_to_globe(ds , ds_global, mask_sum)\n",
    "                    \n",
    "                    \n",
    "                    file_name = 'EM_Earth_probabilistic_daily_'+variable+'_global_'+\\\n",
    "                                year+month+'_'+ensemble+'.nc'\n",
    "                    folder_name = root_save+'probabilistic_daily_global/'+variable+'/'+\\\n",
    "                                year+month+'/'\n",
    "                    if not os.path.isdir(folder_name):\n",
    "                        os.makedirs(folder_name)\n",
    "                    \n",
    "                    for name, value in ds_global.items():\n",
    "                        for t in range(value.shape[0]):\n",
    "                            temp = np.array(value[t,:,:]) / mask_sum[name]\n",
    "                            temp[mask_sum[name] == 0] = -9999\n",
    "                            value[t, :, :] = temp\n",
    "                        ds_global[name] = value\n",
    "                    \n",
    "                    print(file_name)\n",
    "                    \n",
    "                    os.system('rm '+folder_name+file_name)\n",
    "                    \n",
    "                    encoding = {}\n",
    "                    for var in ds_global.data_vars:\n",
    "                        encoding[var] = {'_FillValue': -9999., 'zlib': True, 'complevel': 4}\n",
    "                        \n",
    "                    ds_global.to_netcdf(folder_name+file_name, unlimited_dims='time', encoding=encoding)\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "def fill_cont_to_globe(ds, ds_global, mask_sum):\n",
    "    \n",
    "    row_start = np.where(np.array(ds_global.lat[:]) == ds.lat.max().item())\n",
    "    row_end   = np.where(np.array(ds_global.lat[:]) == ds.lat.min().item())\n",
    "    col_start = np.where(np.array(ds_global.lon[:]) == ds.lon.min().item())\n",
    "    col_end   = np.where(np.array(ds_global.lon[:]) == ds.lon.max().item())\n",
    "    row_start = row_start[0].item()\n",
    "    row_end   = row_end[0].item()\n",
    "    col_start = col_start[0].item()\n",
    "    col_end   = col_end[0].item()\n",
    "    \n",
    "    print(row_start, row_end, col_start, col_end)\n",
    "    \n",
    "    for v in ds.data_vars:\n",
    "        \n",
    "        #\n",
    "        datav = ds[v].values.copy()\n",
    "        datav[np.isnan(datav)] = 0 # replace NaN with 0\n",
    "        ds_global[v][:, row_start:row_end+1, col_start:col_end+1] = \\\n",
    "        ds_global[v][:, row_start:row_end+1, col_start:col_end+1] + datav\n",
    "\n",
    "        #\n",
    "        datav = ds[v].values.copy()\n",
    "        datav = np.array(datav[0,:,:])\n",
    "\n",
    "        datav[~np.isnan(datav)] = 1\n",
    "        datav[np.isnan(datav)] = 0\n",
    "        mask_sum[v][row_start:row_end+1, col_start:col_end+1] = \\\n",
    "        mask_sum[v][row_start:row_end+1, col_start:col_end+1] + datav\n",
    "        \n",
    "    \n",
    "    return ds_global, mask_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the files from HTTP\n",
    "download_EM_ERATH(years = ['1950','2019'],\n",
    "                  months = ['01','02'],\n",
    "                  ensembles = ['001','002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67639d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the files\n",
    "merging_EM_ERATH(years = ['1950','2019'],\n",
    "                 months = ['01','02'],\n",
    "                 ensembles = ['001','002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# ds_global = xr.open_dataset('../EM_Earth_v1/probabilistic_daily_global/prcp/200001/EM_Earth_probabilistic_daily_prcp_global_200001_001.nc')\n",
    "# ds_global = ds_global.sel(time=slice('2000-01-01'))\n",
    "# ds_global = ds_global.squeeze()\n",
    "# ds_global = ds_global['prcp'].to_dataframe()\n",
    "# ds_global = ds_global.reset_index()\n",
    "# ds_global = ds_global.drop(columns=['time'])\n",
    "# ds_global['lat'] = ds_global['lat'].round(2)\n",
    "# ds_global['lon'] = ds_global['lon'].round(2)\n",
    "# print(ds_global)\n",
    "\n",
    "\n",
    "# ds = xr.open_dataset('../EM_Earth_v1/probabilistic_daily/prcp/NorthAmerica/200001/EM_Earth_probabilistic_daily_prcp_NorthAmerica_200001_001.nc')\n",
    "# ds = ds.sel(time=slice('2000-01-01'))\n",
    "# ds = ds.squeeze()\n",
    "# ds = ds['prcp'].to_dataframe()\n",
    "# ds = ds.reset_index()\n",
    "# ds = ds.drop(columns=['time'])\n",
    "# ds['lat'] = ds['lat'].round(2)\n",
    "# ds['lon'] = ds['lon'].round(2)\n",
    "# print(ds)\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# ds_new = pd.merge(ds_global, ds,  how='right', left_on=['lat','lon'], right_on = ['lat','lon'])\n",
    "# ds_new['diff'] = ds_new['prcp_x']-ds_new['prcp_y']\n",
    "# print(ds_new['diff'].abs().sum())\n",
    "# print(ds_new)\n",
    "\n",
    "\n",
    "# ds_new['prcp_x'].plot()\n",
    "# ds_new['prcp_y'].plot()\n",
    "# ds_new['diff'].plot()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "myenv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
